{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c8f4ed",
   "metadata": {},
   "source": [
    "# Lab2 - Data Collection and Pre-processing-Jahnavi Pakanati-9013742"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e9baf6",
   "metadata": {},
   "source": [
    "# Importing the required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "49843bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dataclasses import field\n",
    "from typing import Optional\n",
    "import re\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47869e7e",
   "metadata": {},
   "source": [
    "# Loading the  raw CSV, displaying the  first 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3b4700fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['date', 'customer_id', 'product', 'price', 'quantity', 'coupon_code', 'shipping_city', 'postal_code']\n",
      "          date  customer_id   product   price  quantity coupon_code  \\\n",
      "0   2025-05-11         1000     Scarf  116.39         1     JEANS10   \n",
      "1   2025-05-03         1001   T-Shirt   90.00         4     WINTER5   \n",
      "2   2025-05-02         1002     Dress   80.00         2  SPRINGSALE   \n",
      "3   2025-05-11         1003    Shorts   37.67         5         NaN   \n",
      "4   2025-05-06         1004  Sneakers   52.64         4    SUMMER15   \n",
      "5   2025-05-08         1005    Jacket  100.86         2    SUMMER15   \n",
      "6   2025-05-11         1006     Dress   40.76         4    SUMMER15   \n",
      "7   2025-05-06         1007     Scarf   68.01         3     CLOTH20   \n",
      "8   2025-05-07         1008    Hoodie  108.53         1         NaN   \n",
      "9   2025-05-08         1009     Dress   66.90         4  SPRINGSALE   \n",
      "10  2025-05-04         1010    Jacket   98.25         2     WINTER5   \n",
      "11  2025-05-11         1011    Shorts  119.88         3    SUMMER15   \n",
      "12  2025-05-03         1012     Scarf   27.47         4         NaN   \n",
      "13  2025-05-04         1013     Scarf   82.19         5  SPRINGSALE   \n",
      "14  2025-05-02         1014       Cap   43.30         1         NaN   \n",
      "15  2025-05-06         1015    Shorts   85.28         4    SUMMER15   \n",
      "16  2025-05-10         1016    Hoodie   93.94         5         NaN   \n",
      "17  2025-05-07         1017       Cap   87.55         4    SUMMER15   \n",
      "18  2025-05-04         1018     Jeans   93.58         1     WINTER5   \n",
      "19  2025-05-05         1019  Sneakers   77.34         1    SUMMER15   \n",
      "\n",
      "   shipping_city  postal_code  \n",
      "0        Halifax        80978  \n",
      "1      Vancouver        89625  \n",
      "2       Edmonton        59331  \n",
      "3       Montreal        68039  \n",
      "4      Vancouver        89625  \n",
      "5       Edmonton        59331  \n",
      "6        Calgary        84850  \n",
      "7        Toronto        84243  \n",
      "8         Ottawa        49640  \n",
      "9        Halifax        80978  \n",
      "10        Ottawa        49640  \n",
      "11        Ottawa        49640  \n",
      "12        Ottawa        49640  \n",
      "13     Vancouver        89625  \n",
      "14       Calgary        84850  \n",
      "15      Edmonton        59331  \n",
      "16        Ottawa        49640  \n",
      "17       Calgary        84850  \n",
      "18     Vancouver        89625  \n",
      "19       Halifax        80978  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/clothing_transactions.csv\")\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(df.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8a1a59",
   "metadata": {},
   "source": [
    "#### Justify dict vs namedtuple vs class (1â€“2 sentences)\n",
    "#### Dictionary--A flexible way to store data using key-value pairs.\n",
    "#### NamedTuple--Like a tuple, but you can access values using names.\n",
    "#### Class--A way to group data and functions together.\n",
    "\n",
    "##### Class is the best option for me because it includes logics like cleaning, transforming and computing totals. So this will allow me to show better modularity and resuability for each transaction object.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52f1d02",
   "metadata": {},
   "source": [
    "##### Implementing the transaction class and using to populate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db14b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class Transaction:\n",
    "    date: str\n",
    "    customer_id: str\n",
    "    product: str\n",
    "    price: float\n",
    "    quantity: int\n",
    "    coupon_code: str\n",
    "    shipping_city: str\n",
    "    postal_code: str\n",
    "    coupon_discount_rate: float = field(default=0.0)  # Deriving from the  coupon_code\n",
    "    days_since_purchase: Optional[int] = field(default=None)  # Deriving  from the  purchase date\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d7546d",
   "metadata": {},
   "source": [
    "##### creating a method as load_transaction  and returning the list of transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5b2b893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transactions(path: str) -> list[Transaction]:\n",
    "    df = pd.read_csv(path)\n",
    "    return [\n",
    "        Transaction(\n",
    "            date=row[\"date\"],\n",
    "            customer_id=row[\"customer_id\"],\n",
    "            product=row[\"product\"],\n",
    "            price=row[\"price\"],\n",
    "            quantity=row[\"quantity\"],\n",
    "            coupon_code=row[\"coupon_code\"],\n",
    "            shipping_city=row[\"shipping_city\"],\n",
    "            postal_code=row[\"postal_code\"],\n",
    "        ) for _, row in df.iterrows()\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66387e3",
   "metadata": {},
   "source": [
    "##### Creatiing method called profile_transactions_summary for gettting min/max/mean of price and unique city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4078f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_transactions_summary(list_of_transactions) -> None:\n",
    "    prices = [float(t.price) for t in list_of_transactions if isinstance(t.price, (int, float))]\n",
    "    cities = {t.shipping_city for t in list_of_transactions}\n",
    "    \n",
    "    print(\"Step 5: Quick Profiling\")\n",
    "    print(f\"Price Stats - Minimun: {min(prices)}, Mean: {sum(prices)/len(prices):.2f}, Maximum: {max(prices)}\")\n",
    "    print(f\"Unique Shipping Cities: {len(cities)}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1429d4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Quick Profiling\n",
      "Price Stats - Minimun: 15.02, Mean: 69.35, Maximum: 119.97\n",
      "Unique Shipping Cities: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_of_transactions= load_transactions(\"data/clothing_transactions.csv\")\n",
    "profile_transactions_summary(list_of_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6c71d",
   "metadata": {},
   "source": [
    "##### Injecting the dirty data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fe76c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_dirty_values(list_of_transactions) -> None:\n",
    "    if len(list_of_transactions) >= 3:\n",
    "        list_of_transactions[22].price = -373435\n",
    "        list_of_transactions[545].price = \"adfadf\"\n",
    "        list_of_transactions[200].price = \"unkown\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc43bcb2",
   "metadata": {},
   "source": [
    "##### Created a function called as clean_invalid_prices and clearning values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "69a1a046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_invalid_prices(list_of_transactions: list) -> None:\n",
    "    before = sum(1 for t in list_of_transactions if not isinstance(t.price, float))\n",
    "    \n",
    "    for t in list_of_transactions:\n",
    "        try:\n",
    "            t.price = float(t.price)\n",
    "            if t.price < 0:\n",
    "                t.price = 0.0\n",
    "        except:\n",
    "            t.price = 0.0\n",
    "\n",
    "    \n",
    "    after = sum(1 for t in list_of_transactions if not isinstance(t.price, float))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c85e6770",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_transactions= load_transactions(\"data/clothing_transactions.csv\")\n",
    "inject_dirty_values(list_of_transactions)\n",
    "clean_invalid_prices(list_of_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06a07cd",
   "metadata": {},
   "source": [
    "##### Making the transformations accordingly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "00c00664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_coupon_discounts(list_of_transactions: list) -> None:\n",
    "    for t in list_of_transactions:\n",
    "        match = re.search(r\"SAVE(\\d+)\", str(t.coupon_code))\n",
    "        t.coupon_discount_rate = int(match.group(1)) / 100 if match else 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c501fad",
   "metadata": {},
   "source": [
    "##### Doing feature engineering adding a method called days_since_purchase and trying to calculate discount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e8f08b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_days_since_purchase(transactions: list) -> None:\n",
    "    today = datetime.today()\n",
    "    for t in transactions:\n",
    "        t.days_since_purchase = (today - pd.to_datetime(t.date)).days\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed361ee",
   "metadata": {},
   "source": [
    "##### created a method for implementing the mini-aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "0ffa7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_revenue_by_city(list_of_transactions: list) -> dict:\n",
    "    city_revenue = defaultdict(float)\n",
    "    for t in list_of_transactions:\n",
    "        if isinstance(t.price, float):\n",
    "            city_revenue [t.shipping_city] += t.price * t.quantity if t.price else 0\n",
    "            \n",
    "    return dict(city_revenue )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8334c0e",
   "metadata": {},
   "source": [
    "##### created a method for serialization and trying to get the json and paraquet fiels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c251677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_cleaned_transactions(transactions: list, json_file: str, parquet_file: str) -> None:\n",
    "    data_records = [transaction.__dict__ for transaction in transactions]\n",
    "    \n",
    "    # Saving  as JSON\n",
    "    with open(json_file, \"w\") as json_out:\n",
    "        json.dump(data_records, json_out)\n",
    "    \n",
    "    # Saving as Parquet\n",
    "    table = pa.Table.from_pandas(pd.DataFrame(data_records))\n",
    "    pq.write_table(table, parquet_file)  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c180f91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5: Quick Profiling\n",
      "Price Stats - Minimun: 0.0, Mean: 69.02, Maximum: 119.97\n",
      "Unique Shipping Cities: 8\n",
      "\n",
      "City Revenue: {'Halifax': 14672.939999999997, 'Vancouver': 20080.270000000008, 'Edmonton': 17604.15, 'Montreal': 17108.41, 'Calgary': 13570.070000000002, 'Toronto': 18650.100000000006, 'Ottawa': 17658.46, 'Winnipeg': 15552.23000000001}\n"
     ]
    }
   ],
   "source": [
    "list_of_transactions = load_transactions(\"data/clothing_transactions.csv\")\n",
    "inject_dirty_values(list_of_transactions)\n",
    "clean_invalid_prices(list_of_transactions)\n",
    "apply_coupon_discounts(list_of_transactions)\n",
    "add_days_since_purchase(list_of_transactions)\n",
    "profile_transactions_summary(list_of_transactions)\n",
    "city_revenue = aggregate_revenue_by_city(list_of_transactions)\n",
    "export_cleaned_transactions(list_of_transactions, \"data/cleaned_transactions.json\", \"data/cleaned_transactions.parquet\")\n",
    "\n",
    "print(\"City Revenue:\", city_revenue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e799d07",
   "metadata": {},
   "source": [
    "##### Brief explanation regarding how I used oop's \n",
    "##### Object-Oriented Programming (OOP) made it easy to divide this project into reusable, modular, and logical components. Encapsulating the # cleaning, transformation, and calculation logic into a class (`Transaction`) allowed adding behavior to each transaction record inline. This enhanced code readability and lowered the error potential since behavior and data were not separate. It also made testing and debugging a single record easier. OOP overall improved code structure and minimized the complexity of working with hundreds of records.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d781b364",
   "metadata": {},
   "source": [
    "##### Merging the both CSV's files Clothing_transactions and address_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8335252",
   "metadata": {},
   "source": [
    "| Field             | Type      | Description                                       | Source                |\n",
    "|------------------|-----------|---------------------------------------------------|------------------------|\n",
    "| date             | string    | Purchase date of the transaction                 |clothing_transactions .csv      |\n",
    "| customer_id      | string    | Unique identifier for each customer              | clothing_transactions.csv      |\n",
    "| product     | string    | Identifier for the product purchased             | clothing_transactions.csv      |\n",
    "| postal_code     | string    | Name of the product                              | address_datasetl.csv     |\n",
    "| street        | string    | Category of the street                        | address_dataset.csv     |\n",
    "| city           |string    | Description of the city                       | address_dataset.csv     |\n",
    "|country        | String   |Description of the country                      |address_dataset.csv\n",
    "|province      | string    | Description of the province                      | address_dataset.csv     |\n",
    "| price            | float     | Unit price of the product                        | clothing_transactions.csv      |\n",
    "| quantity         | int       | Quantity purchased                               | clothing_transactions.csv      |\n",
    "| coupon_code      | string    | Promotional code used for the transaction        | clothing_transactions.csv      |\n",
    "| shipping_city    | string    | City where the product is being shipped          | clothing_transactions.csv      |\n",
    "| discount_pct     | float     | Numeric discount derived from coupon_code        | Derived                |\n",
    "| days_since_purchase | int   | Days since the transaction date                  | Derived                |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
